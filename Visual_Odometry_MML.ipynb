{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pwcnet",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ItsMeDarshan/Deep-Learning/blob/master/Visual_Odometry_MML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayHF7apPBmFv"
      },
      "source": [
        "##PWCNET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2EWIyyX5skK"
      },
      "source": [
        "####Download datasets to the virtual machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk_3a4tti2zR"
      },
      "source": [
        "%%capture\r\n",
        "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_scene_flow.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCJVvCV1QShv"
      },
      "source": [
        "%%capture\r\n",
        "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_odometry_gray.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BPhCJsv55N5"
      },
      "source": [
        "####Unzip data and store at a particular place(inside the virtual machines's provided memory)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkOYw69RRQ7z",
        "outputId": "41bbd053-9a1b-4425-c31a-287e15234201"
      },
      "source": [
        "\r\n",
        "!unzip data_odometry_gray.zip -d \"/content/Kitti_odo\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data_odometry_gray.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of data_odometry_gray.zip or\n",
            "        data_odometry_gray.zip.zip, and cannot find data_odometry_gray.zip.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm4Js4VCjVc_"
      },
      "source": [
        "%%capture\r\n",
        "!unzip data_scene_flow.zip -d \"/content/Kitti2015\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1mFyWQg_P9-"
      },
      "source": [
        "%%capture\r\n",
        "#!wget http://files.is.tue.mpg.de/sintel/MPI-Sintel-complete.zip\r\n",
        "!unzip \"/content/pwcnet/content/pwcnet/MPI-Sintel-complete.zip\" -d \"/content/Sintel\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To1Aq6-q6QcI"
      },
      "source": [
        "####Clone the PWCNET Repo(again inside the virtual machines's provided memory)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfHPw8nXju7V"
      },
      "source": [
        "%%capture\n",
        "%cd /content\n",
        "!rm -r pwcnet\n",
        "!git clone https://github.com/daigo0927/pwcnet\n",
        "%cd pwcnet\n",
        "#!git checkout tf2\n",
        "!git submodule init\n",
        "!git submodule update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SleRQ9l6gBS"
      },
      "source": [
        "####Print current working directory and list the sub directories and files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiZQCrEik0ia",
        "outputId": "74291813-6821-4f66-ebdc-3ff09e1d6ad3"
      },
      "source": [
        "#!pip list | grep tensorflow\n",
        "!echo $PWD\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pwcnet\n",
            "datahandler\tlosses.py\t\t   modules.py\t       test.py\n",
            "flow_color.pdf\tmodel_1000epochs\t   README.md\t       train.py\n",
            "flow_utils.py\tmodel_100epochs_ft_Chairs  requirements.txt    utils.py\n",
            "__init__.py\tmodel_250epochs_ft_Final   sample\n",
            "LICENSE\t\tmodel.py\t\t   test_continuous.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlttjKzd6vuI"
      },
      "source": [
        "####check if there is GPU available, if available then print its name and device number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqcowj9HEHq1",
        "outputId": "56d45fcc-ea4c-4b7c-fd55-e4e8403cec76"
      },
      "source": [
        "# edit *.py files to add line for GPU to use.\r\n",
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "print(device_name)\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  os.system('sed -i \"s/os.environ\\\\[\\'CUDA_VISIBLE_DEVICES\\'\\\\] = input/os.environ[\\'CUDA_VISIBLE_DEVICES\\'] = \\'-1\\' # input/g\" /content/pwcnet/*.py')\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "else:\r\n",
        "  os.system('sed -i \"s/os.environ\\\\[\\'CUDA_VISIBLE_DEVICES\\'\\\\] = input/os.environ[\\'CUDA_VISIBLE_DEVICES\\'] = \\'0\\' # input/g\" /content/pwcnet/*.py')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK5-avLx696i"
      },
      "source": [
        "#### command for adding tensorflow 1 compatibility as current google colab VM has tensorflow 2 so some commands won't work\r\n",
        "\r\n",
        "ayushi, you solved this error of **\"can't read ./*.py: No such file or directory\"**. Can you resolve it again? It seems the issue came again or the new command was not stored correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtjYEvJhkN9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c91b694-cf76-48b8-a1b5-6c4e3d9991a0"
      },
      "source": [
        "!sed -i 's/^\\s*import tensorflow as.*/import tensorflow.compat.v1 as tf\\ntf.disable_v2_behavior()/g' ./*.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sed: can't read ./*.py: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k6lnOKhqAx9"
      },
      "source": [
        "#!sed -i 's/from\\smodules/from pwcnet.modules/g' pwcnet/*.py | grep modules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVrOSNer7CNu"
      },
      "source": [
        "####command for training PWCNET on KITTI dataset. \r\n",
        "```please note that the crop shape should be the multiple of 64```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4ZtsD54j2oR"
      },
      "source": [
        "\n",
        "#[384, 448]\n",
        "\n",
        "# Added --crop_shape 320 1216 - Avinash\n",
        "!python train.py --dataset KITTI --dataset_dir /content/Kitti2015 --crop_shape 320 1216"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cy2MDOaSvoi",
        "outputId": "642433d1-b9fb-47a2-fdef-8b4d1eba0a16"
      },
      "source": [
        "#!wget https://drive.google.com/drive/folders/1q3pKFc3hThZ4mR4mHV1_sxqX09GeoF7W?usp=sharing\r\n",
        "!unzip \"/content/1q3pKFc3hThZ4mR4mHV1_sxqX09GeoF7W?usp=sharing\" -d \"/content/kitti_odometry\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/1q3pKFc3hThZ4mR4mHV1_sxqX09GeoF7W?usp=sharing\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/1q3pKFc3hThZ4mR4mHV1_sxqX09GeoF7W?usp=sharing or\n",
            "        /content/1q3pKFc3hThZ4mR4mHV1_sxqX09GeoF7W?usp=sharing.zip, and cannot find /content/1q3pKFc3hThZ4mR4mHV1_sxqX09GeoF7W?usp=sharing.ZIP, period.\n",
            "\n",
            "No zipfiles found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5rZrtgl8Wy7"
      },
      "source": [
        "####Mounting Google Drive on the VM(current session)\r\n",
        "```Please note that if your session expired or gets closed then the drive will be automatically unmounted from the VM```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrB8j-qMXkl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc560a2-eee1-487f-bf00-a82c9b117ef7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osjjO1F68v-T"
      },
      "source": [
        "####remove a folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5oGgNUdSFzg"
      },
      "source": [
        "!rm -rf \"/content/pwcnet/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzMPRcSI84Lb"
      },
      "source": [
        "####Unzip command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic9vu1hwHxaS"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/VO/pwcnetzip/pwcnet.zip\" -d \"/content/pwcnet\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDPmJqJZ9Auo"
      },
      "source": [
        "####Repetitively moving a directory from one place to another"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob7UaKqp3Vnk"
      },
      "source": [
        "#!mkdir Pwcnet\r\n",
        "!mv -R \"/content/pwcnet/content/pwcnet/*\" \"/content/Pwcnet\"\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rlmztIK9Wkg"
      },
      "source": [
        "####Testing the trained PWCNET(continuously iterating over the set of images) by taking stored model weights(three files are stored by PWCNET after 1 successful epoch training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWxht7tzUALD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "844a91a5-60ec-4919-a25c-d7d2407b6814"
      },
      "source": [
        "# %cd pwcnet\r\n",
        "# figures will be in test_figure folder\r\n",
        "!python test_continuous.py -i /content/Kitti2015/testing/image_2/* -r /content/drive/MyDrive/VO/colab_pwcnet/model/model_100.ckpt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'test_continuous.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRxZisRyAcAZ"
      },
      "source": [
        "####Testing the trained PWCNET(takes only two images) by taking stored model weights(three files are stored by PWCNET after 1 successful epoch training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHWCtY1NQ-4l"
      },
      "source": [
        "\r\n",
        "!python /content/Pwcnet/pwcnet/test.py --input_images /content/Sintel/training/final/alley_1/frame_0004.png /content/Sintel/training/final/alley_1/frame_0005.png --resume /content/drive/MyDrive/VO/colab_pwcnet/model/model_100.ckpt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KXmjf3ZAmns"
      },
      "source": [
        "####Using CV2 library to get shape of an image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glfyTtg5PCNj"
      },
      "source": [
        "import cv2\r\n",
        "img = cv2.imread(\"/content/test_figure/test_alley_1_frame_0004.png\")\r\n",
        "print(img.shape)\r\n",
        "print(img)\r\n",
        "#(438, 1170, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivqPxIcvBdSt"
      },
      "source": [
        "####Zip a folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aee6ragaAEt1"
      },
      "source": [
        "!zip -r \"/content/drive/MyDrive/VO/pwcnetzip/pwcnet\"  \"/content/pwcnet\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G59UAgd3ivPV"
      },
      "source": [
        "#ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyQZnUwsBws5"
      },
      "source": [
        "####Import necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5WjOr9tVbmz"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5avJOKMB1VQ"
      },
      "source": [
        "####Get pretrained ResNet50 model with weights trained using ImageNet dataset without including the top(classification) layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEyjYqABi2PW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92cd48f4-c13f-4d8d-e646-75f171f81a36"
      },
      "source": [
        "base_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(438, 1170, 3))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIqKMZiICDBt"
      },
      "source": [
        "####Print the ResNet50 Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEOMSCAFi3iR"
      },
      "source": [
        "base_model.summary()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2FHSwdsCN4J"
      },
      "source": [
        "####Define the top NN layers for R and T matrices(total 6 final values)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fELqXH8NjB6a"
      },
      "source": [
        "\r\n",
        "\r\n",
        "Rot = tf.keras.models.Sequential()\r\n",
        "Rot.add(tf.keras.Input(shape=(2072,))) #change the input shape based on the flatten layer \r\n",
        "Rot.add(tf.keras.layers.Dense(128, activation='relu'))\r\n",
        "Rot.add(tf.keras.layers.Dense(32, activation='relu'))\r\n",
        "Rot.add(tf.keras.layers.Dense(3))\r\n",
        "\r\n",
        "Trans = tf.keras.models.Sequential()\r\n",
        "Trans.add(tf.keras.Input(shape=(2072,)))\r\n",
        "Trans.add(tf.keras.layers.Dense(128, activation='relu'))\r\n",
        "Trans.add(tf.keras.layers.Dense(32, activation='relu'))\r\n",
        "Trans.add(tf.keras.layers.Dense(3))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E53RjTm-CkWl"
      },
      "source": [
        "####Add all these above defined layers to the pretrained model and construct the architecture again. Concatenate both 3,3 values in the final layer and give the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmdGbJyFjEip"
      },
      "source": [
        "#(320,1216,3)\r\n",
        "inputs = tf.keras.Input(shape=(438, 1170, 3))\r\n",
        "x = base_model(inputs)\r\n",
        "x = tf.keras.layers.Conv2D(4, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\r\n",
        "x = tf.keras.layers.BatchNormalization()(x)\r\n",
        "x = tf.keras.layers.Activation(tf.keras.activations.relu)(x)\r\n",
        "flatten_layer = tf.keras.layers.Flatten()(x)\r\n",
        "rot_outputs = Rot(flatten_layer)\r\n",
        "trans_outputs = Trans(flatten_layer)\r\n",
        "concatted = tf.keras.layers.Concatenate()([rot_outputs, trans_outputs])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmuaDpQbDttp"
      },
      "source": [
        "####Define the final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pL0oSfnjGq2"
      },
      "source": [
        "ResNet_model = tf.keras.Model(inputs, concatted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5iO_I0_D4H_"
      },
      "source": [
        "####Recheck the model(by printing summary)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCUbrg76jImj"
      },
      "source": [
        "ResNet_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEvhDBIso_ai"
      },
      "source": [
        "#train_generator = train_datagen.flow_from_directory(\r\n",
        "     # train_dir,\r\n",
        "     #  target_size=(48,48),\r\n",
        "     #   batch_size=64,\r\n",
        "     #    color_mode=\"gray_framescale\",\r\n",
        "     #    class_mode='categorical')\r\n",
        "from keras.optimizers import Adam\r\n",
        "ResNet_model.compile(loss=tf.keras.losses.KLDivergence(),optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\r\n",
        "history=ResNet_model.fit(x_train,y_train,batch_size=32,epochs=10,verbose=1,validation_data=(x_test,y_test),callbacks=[check_point])\r\n",
        "\r\n",
        "#ResNet_model.save_weights('model.h5')\r\n",
        "#model_info = ResNet_model.fit_generator(\r\n",
        "#        train_generator,\r\n",
        "#        steps_per_epoch=28709 // 64,\r\n",
        "#        epochs=50,\r\n",
        "#        validation_data=validation_generator,\r\n",
        "#        validation_steps=7178 // 64)\r\n",
        "\r\n",
        "for image_to_rotate in os.listdir(path):\r\n",
        "        #do training\r\n",
        "#change this\r\n",
        "prediction = emotion_model.predict(cropped_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JNSNUzbG0zy"
      },
      "source": [
        "####Editing the test file(which is under PWCNET's repo) code and making it a module so that it can be integrated with ResNet in the final model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iir7H-8OgVUU"
      },
      "source": [
        "from tensorflow.python.framework import ops\r\n",
        "ops.reset_default_graph()\r\n",
        "from pwctest import Tester\r\n",
        "\r\n",
        "#args = {\"input_images\" = ['/content/Sintel/training/final/alley_1/frame_0004.png', '/content/Sintel/training/final/alley_1/frame_0005.png'], \"resume\" = '/gdrive/MyDrive/VO/colab_pwcnet/model/model_100.ckpt',\"time\" = False}\r\n",
        "args = {}\r\n",
        "args [\"input_images\"] = ['/content/Sintel/training/final/alley_1/frame_0004.png', '/content/Sintel/training/final/alley_1/frame_0005.png']\r\n",
        "args[\"resume\"] = '/content/drive/MyDrive/VO/colab_pwcnet/model/model_100.ckpt'\r\n",
        "args[\"time\"] = False\r\n",
        "Tester(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r45Tx4uCDLDT"
      },
      "source": [
        "!python test_continuous.py -i /content/drive/MyDrive/VO/kitti_odo/Kitti_odometry_Dataset/00/image_0/* -r /content/drive/MyDrive/VO/colab_pwcnet/model/model_100.ckpt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-Rx9Y3ZEq-l"
      },
      "source": [
        "####Path to the optical flow images which were generated using PWCNET and Kitti's 00 image set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CEGfv_gjudr"
      },
      "source": [
        "/content/drive/MyDrive/VO/pwcnetzip/pwcnet_unzipped/content/pwcnet/test_figure/image_0/000000.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuo_M_FhHT0H"
      },
      "source": [
        "#TartanVO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaNX93HgGeDW"
      },
      "source": [
        "####code meant to work on tartanVO github repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX37V4mDjTKt"
      },
      "source": [
        "!python vo_trajectory_from_folder.py  --model-name tartanvo_1914.pkl --kitti --batch-size 2 --worker-num 0 --test-dir data/KITTI_10/image_left --pose-file data/KITTI_10/pose_left.txt --save-flow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI_O0waAHLSo"
      },
      "source": [
        "####Meant for TartanVO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siuNMxPCjO8_"
      },
      "source": [
        "!mkdir models\r\n",
        "!wget https://cmu.box.com/shared/static/t1a5u4x6dxohl89104dyrsiz42mvq2sz.pkl -O models/tartanvo_1914.pkl\r\n",
        "!git clone https://github.com/castacks/tartanvo.git\r\n",
        "!mkdir data\r\n",
        "!wget https://cmu.box.com/shared/static/nw3bi7x5vng2xy296ndxt19uozpk64jq.zip -O data/KITTI_10.zip\r\n",
        "!unzip -q data/KITTI_10.zip -d data/KITTI_10/\r\n",
        "!mkdir data\r\n",
        "!wget https://cmu.box.com/shared/static/1ctocidptdv1xev6pjxdj0b782mrstps.zip -O data/EuRoC_V102.zip\r\n",
        "!unzip -q data/EuRoC_V102.zip -d data/EuRoC_V102/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}